{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62986149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm, trange\n",
    "import datasets as hf\n",
    "hf.disable_caching()\n",
    "import sys\n",
    "if (cvq_util_path:=\"transforming/commavq/utils\") not in sys.path:\n",
    "    sys.path += [cvq_util_path]\n",
    "from video import transpose_and_clip, write_video\n",
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "from transforming.train import run_experiment\n",
    "from transforming.config_objects import *\n",
    "from transforming.text_task.data import IdxDataset\n",
    "from transforming.commavq.data import CommaVQDataset\n",
    "from transforming.network import Transformer\n",
    "from transforming import utils\n",
    "from transforming import metrics\n",
    "from transforming import net_utils\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# set up autoreloading of shared code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hf.load_dataset(\"commaai/commavq\", data_dir=\"/scratch/ssd004/scratch/jackk/commavq/\", cache_dir=\"/scratch/ssd004/scratch/jackk/commavq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a9ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = CommaVQDataset([ds[f'{i}'] for i in range(2)], ExperimentCfg(), CommaVQDatasetCfg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in tr_ds.dset:\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d662a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in tr_ds.dataloader():\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b['xy'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dbb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/scratch/ssd004/scratch/jackk/1-billion-word-language-modeling-benchmark-r13output\"\n",
    "\n",
    "exp_config = ExperimentCfg(vec_size=1536,\n",
    "                        n_layer=12,\n",
    "                        n_heads=12,\n",
    "                        lr_max=2e-4,\n",
    "                        lr_min=1e-7,\n",
    "                        block_size=1024,\n",
    "                        batch_size=2,\n",
    "                        grad_accum_steps=128,\n",
    "                        train_steps=500, # num macro batches\n",
    "                        num_eval=300,  # num micro batches\n",
    "                        dtype=\"float16\",\n",
    "                        compile=True,\n",
    "                        zero=True,\n",
    "                        checkpointing=False,\n",
    "                        normalizer_type=\"RMSNorm\",\n",
    "                        rmsnorm_p=0.1,\n",
    "                        layer_norm_posn=\"pre\",\n",
    "                        posn_embed_type=\"none\",\n",
    "                        relative_float32_attn=False,\n",
    "                        flash=True,\n",
    "                        learnable_unembed=True,\n",
    "                        job_id=9961646\n",
    "                        )\n",
    "if False:  # if dry run, overwrite config with dry_run config\n",
    "    exp_config = exp_config.get_dry()\n",
    "\n",
    "exp_config.ddp = True\n",
    "\n",
    "dset_config = DatasetCfg(dataset_path=data_dir,\n",
    "                        num_workers=4\n",
    "                        )\n",
    "\n",
    "datasets = dict(train=IdxDataset(\"train.bin\", exp_config, dset_config),\n",
    "                eval=IdxDataset(\"eval.bin\", exp_config, dset_config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed727716",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Transformer(exp_config, datasets[\"train\"].cfg, no_init=True)#.to(\"cuda:0\")\n",
    "resumer = net_utils.Resumer(\"resumes/none_posn_unembed_learnable.ckpt\", net, resume=False)\n",
    "resumer.wandb_run_id = \"1qf2k10e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8756078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Transformer(\"/checkpoint/jackk/9898689/large-multi-gpu-zero-relposn-smooth.ckpt\", exp_config, datasets[\"train\"].cfg).to(\"cuda:0\")\n",
    "# net.load_model_state_dict(\"cuda:0\")\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35060bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.sample_random_sentences(net, datasets, exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ec016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import mul\n",
    "from functools import reduce\n",
    "results = {}\n",
    "for name, p in net.named_parameters():\n",
    "    total_size = reduce(mul, p.shape)\n",
    "    # n_nan = p.isnan().sum()\n",
    "    # results[name] = n_nan/total_size\n",
    "    num_select = int(0.05 * total_size)\n",
    "    results[name] = torch.topk(abs(p).flatten(), num_select).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ac953",
   "metadata": {},
   "outputs": [],
   "source": [
    "results  # based on late stage, float 32 relative posn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478887a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = datasets[\"train\"][8]\n",
    "encoder = datasets[\"train\"].encoder\n",
    "print(example[0])\n",
    "print(encoder.decode(example[0].numpy(), split=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cfg.relative_float32_attn = True\n",
    "net.initialize_architecture()\n",
    "net = net.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f0d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # float32 = False\n",
    "    net.train()\n",
    "    final = net(example[0].cuda(0).unsqueeze(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # float32 = True\n",
    "    net.train()\n",
    "    final = net(example[0].cuda(0).unsqueeze(0)).squeeze() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4819768",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    net.train()\n",
    "    final = net(example[0].cuda(0).unsqueeze(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generate(encoder, 'Official , and the government \\'s \" The Daily Show \" and \" The Daily Show \" were all in a hurry to get back to work .\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103813c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # old, before adding float 32 relative position \n",
    "    net.train()\n",
    "    final = net(example[0].cuda(0).unsqueeze(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.decode(final.argmax(dim=-1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ed279",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_posn = net.blocks[11].mha.shifted_posn.squeeze().cpu() / np.sqrt(net.blocks[-1].mha.head_size)\n",
    "max_shifted = torch.clamp(torch.softmax(query_posn, dim=-1).sum(dim=0), 0, 1)\n",
    "select = max_shifted #torch.cat([max_shifted[:, :140], max_shifted[:, -140:]], dim=-1)\n",
    "# print(max_shifted)\n",
    "# print(query_posn)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(select.numpy(), cmap=\"bwr\", vmin=-select.abs().max(), vmax=select.abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.blocks[7].mha.attn_dots[0, 11, 96].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d829aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(net.blocks[7].mha.query_posn, dim=-1).isnan().nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.full((1024,), -80000_00000.0, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.blocks[7].mha.query_posn.isinf().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d3f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(net.blocks[7].mha.query_posn[0,11,230]+1e-8, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3aa176",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(net.blocks[7].mha.query_posn, dim=-1)[0,11,230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7331077",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(net.blocks[7].mha.query_posn[0,11].cpu().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20aebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {k: dict(train=[], eval=[]) for k in [\"loss\", \"perplexity\", \"accuracy\"]}\n",
    "exp_config.num_eval = 50\n",
    "metrics.evaluate(net, datasets, exp_config, all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ab3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics[\"perplexity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cdae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.decode(final.argmax(dim=1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08909920",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config.vec_size = 1280\n",
    "exp_config.n_layer = 5\n",
    "net = Transformer(\"\", exp_config, datasets[\"train\"].cfg).to(\"cuda:0\")\n",
    "simple_inpt = torch.from_numpy(np.asarray([5, 2])).cuda(0).unsqueeze(0)\n",
    "simple_outpt = torch.from_numpy(np.asarray([2, 9])).cuda(0).unsqueeze(0)\n",
    "opt = torch.optim.SGD(net.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = net(simple_inpt, simple_outpt)[0]\n",
    "loss.backward()\n",
    "print(net.embed.weight.grad)\n",
    "opt.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb91eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add_activation_checkpointing()\n",
    "loss = net(simple_inpt, simple_outpt)[0]\n",
    "loss.backward()\n",
    "print(net.embed.weight.grad)\n",
    "opt.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5816ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch_idx = 50\n",
    "    encoder = datasets[\"train\"].encoder\n",
    "    x_example, y_example = datasets[\"train\"][batch_idx][0].cuda(0).unsqueeze(0), datasets[\"train\"][batch_idx][1].cuda(0).unsqueeze(0)\n",
    "    print(encoder.decode(x_example.cpu().numpy().squeeze(), split=True)[:20])\n",
    "    print(encoder.decode(y_example.cpu().numpy().squeeze(), split=True)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af47b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generate(encoder, \" Analysts warned that\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()\n",
    "ans = net(x_example, y_example)\n",
    "print(encoder.decode(ans[1][0][:20].argmax(dim=-1).cpu().numpy()))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bed0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generate(datasets[\"train\"].encoder, prompt=\"In other news,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c96876",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generate(datasets[\"train\"].encoder, prompt=\"The people were arrested on suspicion\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a41876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generate(datasets[\"train\"].encoder, \n",
    "             'Evaluate the truthfullness of the following statement: \"Paris is the Capital of France.\"\\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cca5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = run_experiment(datasets, \"transformer-experiments-google-1-billion\", \"checkpoints/small-1-gpu.ckpt\", exp_config, compile=False)\n",
    "lrs = lrs[599_000:602_000]\n",
    "plt.plot(lrs)\n",
    "plt.gca().set_yscale('log')\n",
    "#plt.hlines([exp_config.lr_min, exp_config.lr_max], 0,len(lrs), linestyle=\"--\")\n",
    "plt.hlines([exp_config.lr_min], 0,len(lrs), linestyle=\"--\")\n",
    "plt.vlines([1_000], exp_config.lr_min, max(lrs), linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1775b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = get_encoder()\n",
    "idx_list = enc.encode(\"Yo what up, that's so call! Indubitably, albeit that's incomprehensively not watto strengthening my resolve?\")\n",
    "print(idx_list)\n",
    "print(enc.decode(idx_list))\n",
    "print(enc.cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197af524",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_files = glob.glob(\"1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/*\")\n",
    "np.random.shuffle(eng_files)\n",
    "enc.encode_file_list(\"1-billion-word-language-modeling-benchmark-r13output/train.bin\", eng_files)\n",
    "\n",
    "eng_files = glob.glob(\"1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/*\")\n",
    "np.random.shuffle(eng_files)\n",
    "enc.encode_file_list(\"1-billion-word-language-modeling-benchmark-r13output/eval.bin\", eng_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = TextDataset(lines)\n",
    "data_dir = \"1-billion-word-language-modeling-benchmark-r13output\"\n",
    "datasets = dict(train=IdxDataset(osp.join(data_dir, \"train\")),\n",
    "                eval=IdxDataset(osp.join(data_dir, \"train\")))\n",
    "dataloaders = {split: DataLoader(dataset, batch_size=16,\n",
    "                            sampler=torch.utils.data.RandomSampler(dataset, replacement=True),\n",
    "                            pin_memory=True,\n",
    "                            num_workers=7) for split,dataset in datasets.items()}\n",
    "print([len(v) for v in dataloaders.values()])\n",
    " #   def __init__(self, vocab_size, n_layer, vec_size, n_heads, block_size):\n",
    "\n",
    "model = Transformer(datasets.vocab_size, n_layer=2, vec_size=120, n_heads=5, block_size=512, save_name=\"gpt1\").to(device)\n",
    "loss_func = F.cross_entropy()\n",
    "optim = torch.nn.optim.Adam(model.parameters())\n",
    "model.load_state_dict(optim=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optim, loss_func, 50, dataloaders, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d67885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cprint(*args):\n",
    "    arr_strs = [str(arr) for arr in args]\n",
    "    lines = [arr_str.split('\\n') for arr_str in arr_strs]\n",
    "    max_lines = max(len(arr_lines) for arr_lines in lines)\n",
    "    \n",
    "    for i in range(max_lines):\n",
    "        row = ''\n",
    "        for arr_lines in lines:\n",
    "            if i < len(arr_lines):\n",
    "                row += arr_lines[i].ljust(len(max(arr_lines, key=len))) + '  '\n",
    "            else:\n",
    "                row += ' ' * len(max(arr_lines, key=len)) + '  '\n",
    "        print(row.rstrip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 512\n",
    "bidirectional = False\n",
    "num_buckets = 16\n",
    "max_distance = 64\n",
    "x = torch.arange(seq_len) + 500\n",
    "x2 = nn.Embedding(seq_len, 1)\n",
    "\n",
    "context_position = torch.arange(seq_len, dtype=torch.long)[:, None]\n",
    "memory_position = torch.arange(seq_len, dtype=torch.long )[None, :]\n",
    "relative_position = memory_position - context_position\n",
    "\n",
    "print(relative_position)\n",
    "\n",
    "relative_buckets = 0\n",
    "if bidirectional:\n",
    "    num_buckets //= 2\n",
    "    relative_buckets += (relative_position > 0).to(torch.long) * num_buckets\n",
    "    relative_position = torch.abs(relative_position)\n",
    "else:\n",
    "    # elementwise minimum, basically zeroes out upper right triangle\n",
    "    relative_position = -torch.min(relative_position, torch.zeros_like(relative_position)) \n",
    "print(relative_position)\n",
    "# now relative_position is in the range [0, inf)\n",
    "\n",
    "# half of the buckets are for single increment\n",
    "max_exact = num_buckets // 2\n",
    "is_small = relative_position < max_exact\n",
    "print(is_small)\n",
    "\n",
    "# The other half of the buckets are for logarithmically bigger bins in positions up to max_distance\n",
    "# seq_len - max_exact is the num of positions we have for the log-bins\n",
    "# but we only want to go up to position max_distance\n",
    "relative_position_if_large = max_exact + (\n",
    "    torch.log(relative_position.float() / max_exact)   # ie. log(rel_posn) - log(max_exact)\n",
    "    / math.log(max_distance / max_exact)  # ie. log(max_distance) - log(max_exact) => at posn max_distance the log -> 1\n",
    "    * (num_buckets - max_exact)   # so that now at max_distance the log is num_buckets - max_exact\n",
    ")\n",
    "print(relative_position_if_large)\n",
    "relative_position_if_large = relative_position_if_large.long()\n",
    "# print(relative_position_if_large)\n",
    "relative_position_if_large = torch.min(                         # ie. basically set stuff past max_position to num_buckets-1\n",
    "    relative_position_if_large, torch.full_like(relative_position_if_large, num_buckets - 1) # set anything that went past num_buckets\n",
    ")                                                                                            # to num_buckets-1\n",
    "                                                                            # we are definietly \"large\" out here, so it makes sense\n",
    "# print(relative_position_if_large)\n",
    "\n",
    "cprint(relative_position, relative_position_if_large)\n",
    "relative_buckets += torch.where(is_small, relative_position, relative_position_if_large)\n",
    "cprint(relative_buckets, relative_position)\n",
    "cprint(relative_buckets[-1][-20:], is_small[-1][-20:])\n",
    "print(torch.take(x, relative_buckets))\n",
    "print(x2.weight.squeeze())\n",
    "print(x2(relative_buckets).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de9790",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((torch.log(relative_position.float() / max_exact) / math.log(max_distance / max_exact))[-1, -66:])\n",
    "print((torch.log(relative_position.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact))[-1, -66:]) #+ max_exact)\n",
    "relative_position_if_large = max_exact + (\n",
    "    torch.log(relative_position.float() / max_exact)\n",
    "    / math.log(max_distance / max_exact)\n",
    "    * (num_buckets - max_exact)\n",
    ")\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c13c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rotary_embedding_torch as ret\n",
    "from einops import rearrange, repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc2042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def theirs(x):\n",
    "    x = rearrange(x, '... (d r) -> ... d r', r = 2)\n",
    "    x1, x2 = x.unbind(dim = -1)\n",
    "    x = torch.stack((-x2, x1), dim = -1)\n",
    "    return rearrange(x, '... d r -> ... (d r)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.arange(2*3*12*32).reshape(2, 3, 12, 32).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4948f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot = ret.RotaryEmbedding(dim=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d0ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = rot.freqs\n",
    "freqs2 = torch.outer(torch.arange(12), freqs)\n",
    "freqs3 = repeat(freqs2, \"... d -> ... (d r)\", r=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb1e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(net_utils.rotate_keys_or_queries(q, freqs3.cos(), freqs3.sin()) == rot.rotate_queries_or_keys(q)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot.rotate_queries_or_keys(q).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4868ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(net_utils.rotate_half(q) == theirs(q)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ed057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += [\"transforming/commavq/utils\"]\n",
    "from video import transpose_and_clip, write_video\n",
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hf.load_dataset(\"commaai/commavq\", data_dir=\"/scratch/ssd004/scratch/jackk/commavq/\", cache_dir=\"/scratch/ssd004/scratch/jackk/commavq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82784fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c456dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb8cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = hf.concatenate_datasets(ds.values()).to_iterable_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc4076",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = ds['40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b7c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d19fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(ds_row):\n",
    "    # print(\"ho\")\n",
    "    tokens = np.load(ds_row['path'])\n",
    "    print(\"init shape\", tokens.shape)\n",
    "    tokens = tokens.reshape(tokens.shape[0], -1)\n",
    "    print(\"next_shape\", tokens.shape)\n",
    "    # prepend BOS_TOKEN\n",
    "    tokens = np.c_[np.ones(len(tokens), dtype=np.int16)*1024, tokens]\n",
    "    print(\"post bos shape\", tokens.shape)\n",
    "    tokens = tokens.reshape(-1)\n",
    "    print(\"post flatten shape\", tokens.shape)\n",
    "    # append EOT_TOKEN\n",
    "    tokens = np.r_[tokens, 1024]\n",
    "    print(\"post eot shape\", tokens.shape)\n",
    "    # print(\"tok shape\", tokens.shape)\n",
    "    return {'ids': tokens.astype(np.int16), 'len': len(tokens.astype(np.int16))}\n",
    "\n",
    "def subsample(example): # definitely shouldn't cache this\n",
    "    start_idx = np.random.randint(0, example['len'] - 1024)\n",
    "    selection = example['ids'][start_idx: start_idx + 1024 + 1]\n",
    "\n",
    "    return {'xy': (selection[:-1], selection[1:])}\n",
    "full_ds = full_ds.map(process).map(subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6abe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in full_ds:\n",
    "    print(b['ids'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f553cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b['ids'][:5], b['ids'][125:135], b['ids'][250:260])\n",
    "print(np.where(b['ids']==1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "b['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "b['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d013d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7af06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16222d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"commaai/commavq\", data_dir=\"/scratch/ssd004/scratch/jackk/commavq/\", cache_dir=\"/scratch/ssd004/scratch/jackk/commavq/\")\n",
    "sess = rt.InferenceSession(\"/scratch/ssd004/scratch/jackk/commavq/commavq/models/decoder.onnx\", rt.SessionOptions(), [\"CUDAExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f2c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(\"/scratch/ssd004/scratch/jackk/commavq/commavq/models/decoder.onnx\", \n",
    "                           rt.SessionOptions(), \n",
    "                           [\"CUDAExecutionProvider\"])\n",
    "video = np.load(ds['0'][0]['path'])\n",
    "pred_frames = []\n",
    "for frame in tqdm(video):\n",
    "    preds = sess.run(None, {\"encoding_indices\": frame[None,...].astype(np.int64)})\n",
    "    pred_frames.append(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84847ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = np.load(ds['1'][40]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(example):\n",
    "    tokens = np.load(example['path'])\n",
    "    tokens = tokens.reshape(tokens.shape[0], -1)\n",
    "    # prepend BOS_TOKEN\n",
    "    tokens = np.c_[np.ones(len(tokens), dtype=np.int16)*1024, tokens]\n",
    "    tokens = tokens.reshape(-1)\n",
    "    # append EOT_TOKEN\n",
    "    tokens = np.r_[tokens, 1024]\n",
    "    return {'ids': tokens.astype(np.int16), 'len': len(tokens.astype(np.int16))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41644fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.map(process,\n",
    "       num_proc=40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

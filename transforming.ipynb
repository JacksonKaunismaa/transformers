{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62986149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "from os import path as osp\n",
    "import json\n",
    "import regex as re  # required since regular re does not support character classes \\p\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from data import *\n",
    "from network import *\n",
    "from train import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data,network,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1775b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = get_encoder()\n",
    "idx_list = enc.encode(\"Yo what up, that's so call! Indubitably, albeit that's incomprehensively not watto strengthening my resolve?\")\n",
    "print(idx_list)\n",
    "print(enc.decode(idx_list))\n",
    "print(enc.cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197af524",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_files = glob.glob(\"1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/*\")\n",
    "np.random.shuffle(eng_files)\n",
    "enc.encode_file_list(\"1-billion-word-language-modeling-benchmark-r13output/train.bin\", eng_files)\n",
    "\n",
    "eng_files = glob.glob(\"1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/*\")\n",
    "np.random.shuffle(eng_files)\n",
    "enc.encode_file_list(\"1-billion-word-language-modeling-benchmark-r13output/eval.bin\", eng_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = TextDataset(lines)\n",
    "data_dir = \"1-billion-word-language-modeling-benchmark-r13output\"\n",
    "datasets = dict(train=IdxDataset(osp.join(data_dir, \"train\")),\n",
    "                eval=IdxDataset(osp.join(data_dir, \"train\")))\n",
    "dataloaders = {split: DataLoader(dataset, batch_size=16,\n",
    "                            sampler=torch.utils.data.RandomSampler(dataset, replacement=True),\n",
    "                            pin_memory=True,\n",
    "                            num_workers=7) for split,dataset in datasets.items()}\n",
    "print([len(v) for v in dataloaders.values()])\n",
    " #   def __init__(self, vocab_size, n_layer, vec_size, n_heads, block_size):\n",
    "\n",
    "model = Transformer(datasets.vocab_size, n_layer=2, vec_size=120, n_heads=5, block_size=512, save_name=\"gpt1\").to(device)\n",
    "loss_func = F.cross_entropy()\n",
    "optim = torch.nn.optim.Adam(model.parameters())\n",
    "model.load_state_dict(optim=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optim, loss_func, 50, dataloaders, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

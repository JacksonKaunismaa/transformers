{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62986149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "# import transformers\n",
    "from transforming.train import run_experiment\n",
    "from transforming.config_objects import ExperimentCfg, DatasetCfg\n",
    "from transforming.data import IdxDataset\n",
    "from transforming.encoder import get_encoder\n",
    "from transforming.network import Transformer\n",
    "from transforming import utils\n",
    "from transforming import metrics\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# set up autoreloading of shared code\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport transforming.train,transforming.config_objects,transforming.data,transforming.encoder,transforming.network\n",
    "%aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dbb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/scratch/ssd004/scratch/jackk/1-billion-word-language-modeling-benchmark-r13output\"\n",
    "\n",
    "exp_config = ExperimentCfg(vec_size=1536,\n",
    "                        n_layer=12,\n",
    "                        n_heads=12,\n",
    "                        lr_max=2e-4,\n",
    "                        lr_min=1e-7,\n",
    "                        block_size=1024,\n",
    "                        batch_size=1,\n",
    "                        grad_accum_steps=256,\n",
    "                        train_steps=500, # num macro batches\n",
    "                        num_eval=300,  # num micro batches\n",
    "                        dtype=\"float16\",\n",
    "                        compile=True,\n",
    "                        zero=True,\n",
    "                        checkpointing=False,\n",
    "                        normalizer_type=\"RMSNorm\",\n",
    "                        rmsnorm_p=0.1,\n",
    "                        layer_norm_posn=\"pre\",\n",
    "                        posn_embed_type=\"relative\",\n",
    "                        flash=False,\n",
    "                        learnable_unembed=True,\n",
    "                        job_id=0,\n",
    "                        relative_float32_attn=True\n",
    "                        )\n",
    "if True:  # if dry run, overwrite config with dry_run config\n",
    "    exp_config = exp_config.get_dry()\n",
    "\n",
    "exp_config.ddp = False\n",
    "\n",
    "dset_config = DatasetCfg(dataset_path=data_dir,\n",
    "                        num_workers=4\n",
    "                        )\n",
    "\n",
    "datasets = dict(train=IdxDataset(\"train.bin\", exp_config, dset_config),\n",
    "                eval=IdxDataset(\"eval.bin\", exp_config, dset_config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Transformer(\"/checkpoint/jackk/9898689/large-multi-gpu-zero-relposn-smooth.ckpt\", exp_config, datasets[\"train\"].cfg).to(\"cuda:0\")\n",
    "# net.load_model_state_dict(\"cuda:0\")\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35060bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.sample_random_sentences(net, datasets, exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ec016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import mul\n",
    "from functools import reduce\n",
    "results = {}\n",
    "for name, p in net.named_parameters():\n",
    "    total_size = reduce(mul, p.shape)\n",
    "    # n_nan = p.isnan().sum()\n",
    "    # results[name] = n_nan/total_size\n",
    "    num_select = int(0.05 * total_size)\n",
    "    results[name] = torch.topk(abs(p).flatten(), num_select).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ac953",
   "metadata": {},
   "outputs": [],
   "source": [
    "results  # based on late stage, float 32 relative posn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478887a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = datasets[\"train\"][8]\n",
    "encoder = datasets[\"train\"].encoder\n",
    "print(example[0])\n",
    "print(encoder.decode(example[0].numpy(), split=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cfg.relative_float32_attn = True\n",
    "net.initialize_architecture()\n",
    "net = net.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f0d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # float32 = False\n",
    "    net.train()\n",
    "    final = net(example[0].cuda(0).unsqueeze(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # float32 = True\n",
    "    net.train()\n",
    "    final = net(example[0].cuda(0).unsqueeze(0)).squeeze() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4819768",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    net.train()\n",
    "    final = net(example[0].cuda(0).unsqueeze(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generate(encoder, 'Official , and the government \\'s \" The Daily Show \" and \" The Daily Show \" were all in a hurry to get back to work .\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103813c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # old, before adding float 32 relative position \n",
    "    net.train()\n",
    "    final = net(example[0].cuda(0).unsqueeze(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.decode(final.argmax(dim=-1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ed279",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_posn = net.blocks[11].mha.shifted_posn.squeeze().cpu() / np.sqrt(net.blocks[-1].mha.head_size)\n",
    "max_shifted = torch.clamp(torch.softmax(query_posn, dim=-1).sum(dim=0), 0, 1)\n",
    "select = max_shifted #torch.cat([max_shifted[:, :140], max_shifted[:, -140:]], dim=-1)\n",
    "# print(max_shifted)\n",
    "# print(query_posn)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(select.numpy(), cmap=\"bwr\", vmin=-select.abs().max(), vmax=select.abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.blocks[7].mha.attn_dots[0, 11, 96].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d829aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(net.blocks[7].mha.query_posn, dim=-1).isnan().nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.full((1024,), -80000_00000.0, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.blocks[7].mha.query_posn.isinf().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d3f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(net.blocks[7].mha.query_posn[0,11,230]+1e-8, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3aa176",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(net.blocks[7].mha.query_posn, dim=-1)[0,11,230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7331077",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(net.blocks[7].mha.query_posn[0,11].cpu().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20aebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {k: dict(train=[], eval=[]) for k in [\"loss\", \"perplexity\", \"accuracy\"]}\n",
    "exp_config.num_eval = 50\n",
    "metrics.evaluate(net, datasets, exp_config, all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ab3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics[\"perplexity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cdae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.decode(final.argmax(dim=1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08909920",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config.vec_size = 1280\n",
    "exp_config.n_layer = 5\n",
    "net = Transformer(\"\", exp_config, datasets[\"train\"].cfg).to(\"cuda:0\")\n",
    "simple_inpt = torch.from_numpy(np.asarray([5, 2])).cuda(0).unsqueeze(0)\n",
    "simple_outpt = torch.from_numpy(np.asarray([2, 9])).cuda(0).unsqueeze(0)\n",
    "opt = torch.optim.SGD(net.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = net(simple_inpt, simple_outpt)[0]\n",
    "loss.backward()\n",
    "print(net.embed.weight.grad)\n",
    "opt.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb91eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add_activation_checkpointing()\n",
    "loss = net(simple_inpt, simple_outpt)[0]\n",
    "loss.backward()\n",
    "print(net.embed.weight.grad)\n",
    "opt.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5816ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch_idx = 50\n",
    "    encoder = datasets[\"train\"].encoder\n",
    "    x_example, y_example = datasets[\"train\"][batch_idx][0].cuda(0).unsqueeze(0), datasets[\"train\"][batch_idx][1].cuda(0).unsqueeze(0)\n",
    "    print(encoder.decode(x_example.cpu().numpy().squeeze(), split=True)[:20])\n",
    "    print(encoder.decode(y_example.cpu().numpy().squeeze(), split=True)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af47b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generate(encoder, \" Analysts warned that\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()\n",
    "ans = net(x_example, y_example)\n",
    "print(encoder.decode(ans[1][0][:20].argmax(dim=-1).cpu().numpy()))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bed0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generate(datasets[\"train\"].encoder, prompt=\"In other news,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c96876",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generate(datasets[\"train\"].encoder, prompt=\"The people were arrested on suspicion\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a41876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generate(datasets[\"train\"].encoder, \n",
    "             'Evaluate the truthfullness of the following statement: \"Paris is the Capital of France.\"\\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cca5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = run_experiment(datasets, \"transformer-experiments-google-1-billion\", \"checkpoints/small-1-gpu.ckpt\", exp_config, compile=False)\n",
    "lrs = lrs[599_000:602_000]\n",
    "plt.plot(lrs)\n",
    "plt.gca().set_yscale('log')\n",
    "#plt.hlines([exp_config.lr_min, exp_config.lr_max], 0,len(lrs), linestyle=\"--\")\n",
    "plt.hlines([exp_config.lr_min], 0,len(lrs), linestyle=\"--\")\n",
    "plt.vlines([1_000], exp_config.lr_min, max(lrs), linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1775b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = get_encoder()\n",
    "idx_list = enc.encode(\"Yo what up, that's so call! Indubitably, albeit that's incomprehensively not watto strengthening my resolve?\")\n",
    "print(idx_list)\n",
    "print(enc.decode(idx_list))\n",
    "print(enc.cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197af524",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_files = glob.glob(\"1-billion-word-language-modeling-benchmark-r13output/training-monolingual.tokenized.shuffled/*\")\n",
    "np.random.shuffle(eng_files)\n",
    "enc.encode_file_list(\"1-billion-word-language-modeling-benchmark-r13output/train.bin\", eng_files)\n",
    "\n",
    "eng_files = glob.glob(\"1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/*\")\n",
    "np.random.shuffle(eng_files)\n",
    "enc.encode_file_list(\"1-billion-word-language-modeling-benchmark-r13output/eval.bin\", eng_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = TextDataset(lines)\n",
    "data_dir = \"1-billion-word-language-modeling-benchmark-r13output\"\n",
    "datasets = dict(train=IdxDataset(osp.join(data_dir, \"train\")),\n",
    "                eval=IdxDataset(osp.join(data_dir, \"train\")))\n",
    "dataloaders = {split: DataLoader(dataset, batch_size=16,\n",
    "                            sampler=torch.utils.data.RandomSampler(dataset, replacement=True),\n",
    "                            pin_memory=True,\n",
    "                            num_workers=7) for split,dataset in datasets.items()}\n",
    "print([len(v) for v in dataloaders.values()])\n",
    " #   def __init__(self, vocab_size, n_layer, vec_size, n_heads, block_size):\n",
    "\n",
    "model = Transformer(datasets.vocab_size, n_layer=2, vec_size=120, n_heads=5, block_size=512, save_name=\"gpt1\").to(device)\n",
    "loss_func = F.cross_entropy()\n",
    "optim = torch.nn.optim.Adam(model.parameters())\n",
    "model.load_state_dict(optim=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optim, loss_func, 50, dataloaders, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d67885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cprint(*args):\n",
    "    arr_strs = [str(arr) for arr in args]\n",
    "    lines = [arr_str.split('\\n') for arr_str in arr_strs]\n",
    "    max_lines = max(len(arr_lines) for arr_lines in lines)\n",
    "    \n",
    "    for i in range(max_lines):\n",
    "        row = ''\n",
    "        for arr_lines in lines:\n",
    "            if i < len(arr_lines):\n",
    "                row += arr_lines[i].ljust(len(max(arr_lines, key=len))) + '  '\n",
    "            else:\n",
    "                row += ' ' * len(max(arr_lines, key=len)) + '  '\n",
    "        print(row.rstrip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 512\n",
    "bidirectional = False\n",
    "num_buckets = 16\n",
    "max_distance = 64\n",
    "x = torch.arange(seq_len) + 500\n",
    "x2 = nn.Embedding(seq_len, 1)\n",
    "\n",
    "context_position = torch.arange(seq_len, dtype=torch.long)[:, None]\n",
    "memory_position = torch.arange(seq_len, dtype=torch.long )[None, :]\n",
    "relative_position = memory_position - context_position\n",
    "\n",
    "print(relative_position)\n",
    "\n",
    "relative_buckets = 0\n",
    "if bidirectional:\n",
    "    num_buckets //= 2\n",
    "    relative_buckets += (relative_position > 0).to(torch.long) * num_buckets\n",
    "    relative_position = torch.abs(relative_position)\n",
    "else:\n",
    "    # elementwise minimum, basically zeroes out upper right triangle\n",
    "    relative_position = -torch.min(relative_position, torch.zeros_like(relative_position)) \n",
    "print(relative_position)\n",
    "# now relative_position is in the range [0, inf)\n",
    "\n",
    "# half of the buckets are for single increment\n",
    "max_exact = num_buckets // 2\n",
    "is_small = relative_position < max_exact\n",
    "print(is_small)\n",
    "\n",
    "# The other half of the buckets are for logarithmically bigger bins in positions up to max_distance\n",
    "# seq_len - max_exact is the num of positions we have for the log-bins\n",
    "# but we only want to go up to position max_distance\n",
    "relative_position_if_large = max_exact + (\n",
    "    torch.log(relative_position.float() / max_exact)   # ie. log(rel_posn) - log(max_exact)\n",
    "    / math.log(max_distance / max_exact)  # ie. log(max_distance) - log(max_exact) => at posn max_distance the log -> 1\n",
    "    * (num_buckets - max_exact)   # so that now at max_distance the log is num_buckets - max_exact\n",
    ")\n",
    "print(relative_position_if_large)\n",
    "relative_position_if_large = relative_position_if_large.long()\n",
    "# print(relative_position_if_large)\n",
    "relative_position_if_large = torch.min(                         # ie. basically set stuff past max_position to num_buckets-1\n",
    "    relative_position_if_large, torch.full_like(relative_position_if_large, num_buckets - 1) # set anything that went past num_buckets\n",
    ")                                                                                            # to num_buckets-1\n",
    "                                                                            # we are definietly \"large\" out here, so it makes sense\n",
    "# print(relative_position_if_large)\n",
    "\n",
    "cprint(relative_position, relative_position_if_large)\n",
    "relative_buckets += torch.where(is_small, relative_position, relative_position_if_large)\n",
    "cprint(relative_buckets, relative_position)\n",
    "cprint(relative_buckets[-1][-20:], is_small[-1][-20:])\n",
    "print(torch.take(x, relative_buckets))\n",
    "print(x2.weight.squeeze())\n",
    "print(x2(relative_buckets).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de9790",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((torch.log(relative_position.float() / max_exact) / math.log(max_distance / max_exact))[-1, -66:])\n",
    "print((torch.log(relative_position.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact))[-1, -66:]) #+ max_exact)\n",
    "relative_position_if_large = max_exact + (\n",
    "    torch.log(relative_position.float() / max_exact)\n",
    "    / math.log(max_distance / max_exact)\n",
    "    * (num_buckets - max_exact)\n",
    ")\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
